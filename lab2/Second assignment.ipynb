{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second assignment: Analyse your \"realistic\" graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections, itertools\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "edges = nx.read_edgelist('../datasets/dataset.txt')\n",
    "G.add_edges_from(edges.edges())\n",
    "posTotal = nx.spring_layout(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/arXivGraph.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print node numbers \n",
    "print(\"Number of nodes:\",G.number_of_nodes())\n",
    "#Print edges number G.number_of_edges()\n",
    "print(\"Number of edges:\",G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset stats (from https://snap.stanford.edu/data/ca-GrQc.html)\n",
    "<img src=\"images/dataset.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node level measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils class\n",
    "\n",
    "class statistics:\n",
    "    \n",
    "    def __init__(self, d, measure):\n",
    "        self.measure = measure\n",
    "        self.orderedList = sorted(list(d.items()), key=lambda pair: pair[1])\n",
    "        self.orderedKeys = sorted(list(d.keys()))\n",
    "        self.orderedValues = sorted(list(d.values()))\n",
    "    \n",
    "    def average(self):    \n",
    "        return np.mean(self.orderedValues)\n",
    "\n",
    "    def variance(self):\n",
    "        return np.var(self.orderedValues)\n",
    "\n",
    "    def maximum(self):\n",
    "        return self.orderedList[-1]\n",
    "\n",
    "    def minimum(self):\n",
    "        return self.orderedList[0]\n",
    "\n",
    "    def median(self):\n",
    "        return self.orderedList[len(self.orderedList)//2]\n",
    "    \n",
    "    def print_info(self):\n",
    "        print(\"{} distribution:\\n\\taverage: {}\\n\\tvariance: {}\\n\\tmaximum: {}\\n\\tminimum: {}\\n\\tmedian: {}\\n\"\n",
    "              .format(self.measure,self.average(),self.variance(),\n",
    "                      self.maximum(),self.minimum(),self.median()))\n",
    "    \n",
    "    def barplot(self):\n",
    "        key, cnt = zip(*collections.Counter(self.orderedValues).items())\n",
    "\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.bar(key, cnt, width=0.80, color='b')\n",
    "        plt.title(self.measure+\" barplot\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xlabel(self.measure)\n",
    "        plt.xticks(key, rotation=90)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def histogram(self, bins=10):\n",
    "        plt.figure(figsize=(15,8))\n",
    "        counts,bins,_ = plt.hist(self.orderedValues, bins=bins)\n",
    "                                  \n",
    "        bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "        for count, x in zip(counts, bin_centers):\n",
    "            # Label the raw counts\n",
    "            plt.annotate(str(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "                         xytext=(0, -20), textcoords='offset points', va='top', ha='center')\n",
    "            # Label the percentages\n",
    "            percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "            plt.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "                         xytext=(0, -35), textcoords='offset points', va='top', ha='center')\n",
    "        \n",
    "        plt.title(self.measure+\" histogram\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks(bins)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/measures/arXivDegree.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_stat = statistics(dict(G.degree),\"Degree\")\n",
    "degree_stat.print_info()\n",
    "degree_stat.barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/measures/arXivBetweenness.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btwc = nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "between_stat = statistics(btwc, \"Betweenness\")\n",
    "between_stat.print_info()\n",
    "between_stat.histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/measures/arXivCloseness.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsn = nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "close_stat = statistics(clsn, \"Closeness\")\n",
    "close_stat.print_info()\n",
    "close_stat.histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td><img src=\"images/measures/arXivClustering.png\"></td>\n",
    "    <td><img src=\"images/measures/arXivTriangles.png\"></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = nx.clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_stat = statistics(cl, \"Clustering\")\n",
    "cluster_stat.print_info()\n",
    "cluster_stat.histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/measures/arXivPagerank.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrnk = nx.pagerank_numpy(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pagerank_stat = statistics(pgrnk, \"Pagerank\")\n",
    "pagerank_stat.print_info()\n",
    "pagerank_stat.histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HITS (hubs = authorities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/measures/arXivHITS.png\">    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs = nx.hits_numpy(G)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs_stat = statistics(hubs, \"HITS (hubs)\")\n",
    "hubs_stat.print_info()\n",
    "hubs_stat.histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph level measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giant component\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = max(nx.connected_component_subgraphs(G), key=len)\n",
    "\n",
    "if(len(G)==len(G0)):\n",
    "    print(\"Largest connected component covers the whole graph\")\n",
    "else:\n",
    "    print(\"The Giant component covers the {}% of the whole graph\".format(round(len(G0)/len(G)*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Girvan-Newman algorithm**\n",
    "1. The betweenness of all existing edges in the network is calculated first.\n",
    "2. The edge with the highest betweenness is removed.\n",
    "3. The betweenness of all edges affected by the removal is recalculated.\n",
    "4. Steps 2 and 3 are repeated until no edges remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communitiesGen_GW = community.girvan_newman(G)\n",
    "top_GW = next(communitiesGen_GW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communitiesGen_giantGW = community.girvan_newman(G0)\n",
    "top_giantGW = next(communitiesGen_giantGW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clauset-Newman-Moore greedy modularity maximization**\n",
    "\n",
    "Greedy modularity maximization begins with each node in its own community and joins the pair of communities that most increases modularity until no such pair exists.\n",
    "\n",
    "modularity is calculated in this way<br>\n",
    "Q = $\\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{k_ik_j}{2m}\\right)\n",
    "            \\delta(c_i,c_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_greedMod = community.greedy_modularity_communities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "communities_giantGreedMod = community.greedy_modularity_communities(G0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communities evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_evaluation(graph, communities, metric):\n",
    "    return metric(graph, communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Girvan-Newman (betweenness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_evaluation(G, top_GW, community.quality.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_evaluation(G, top_GW, community.quality.modularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_evaluation(G, top_GW, community.quality.performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Clauset-Newman-Moore (greedy modularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_evaluation(G, communities_greedMod, community.quality.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_evaluation(G, communities_greedMod, community.quality.modularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_evaluation(G, communities_greedMod, community.quality.performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communities visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_communities(graph, comms):\n",
    "    llist = [] # build a list of color for each community\n",
    "    for node in graph:\n",
    "        for i,comm in enumerate(comms):\n",
    "            if node in comm:\n",
    "                llist.append(i)\n",
    "                break    \n",
    "    vmax = len(np.unique(llist))-1\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    nx.draw_networkx(graph,node_color=llist,cmap = 'jet',vmin = 0,vmax=vmax,font_size=0,node_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Girvan-Newman (betweenness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_communities(G, top_GW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_communities(G0, top_GW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Clauset-Newman-Moore (greedy modularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_communities(G, communities_greedMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_communities(G0, communities_greedMod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures summary of the whole graph and giant component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- general statistics of the whole graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stats on the whole graph\n",
    "density = nx.density(G)\n",
    "avg_clust = nx.average_clustering(G)\n",
    "trans = nx.transitivity(G)\n",
    "assrt = nx.degree_pearson_correlation_coefficient(G)\n",
    "diameter = float(\"Inf\")\n",
    "avg_path_lenght = float(\"Inf\")\n",
    "if(nx.is_connected(G)): # if is not connected we could not compute diameter and avg path length\n",
    "    diameter = nx.diameter(G)\n",
    "    avg_path_lenght = nx.average_shortest_path_length(G)\n",
    "\n",
    "print(\"avg degree: \", degree_stat.average())\n",
    "print(\"density: \", density)\n",
    "print(\"diameter: \", diameter)\n",
    "print(\"avg_path_lenght: \", avg_path_lenght)\n",
    "print(\"avg_clustering coeff: \", avg_clust)\n",
    "print(\"transitivity: \", trans)\n",
    "print(\"assortativity: \", assrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- assortativity measures of the whole graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,10))\n",
    "plt.title(\"Degree Correlation Matrix\")\n",
    "sns.heatmap(nx.degree_mixing_matrix(G), cmap=\"coolwarm\").invert_yaxis();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(nx.k_nearest_neighbors(G).values())\n",
    "pairs = sorted(nx.k_nearest_neighbors(G).items(), key=lambda pair:pair[0])\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Average Degree Connectivity\")\n",
    "plt.plot(list(map(lambda pair:pair[1], pairs)))\n",
    "plt.xticks(range(len(pairs)),list(map(lambda pair:pair[0], pairs)))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = list(map(lambda pair: pair[1], sorted(nx.average_neighbor_degree(G).items(), key=lambda pair:pair[0])))\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Average Neighbors Degree Value\")\n",
    "plt.plot(vals, 'o')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- general statistics of the giant component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats on the Giant Component\n",
    "degrees = [val for (node, val) in G0.degree]\n",
    "avg_degree = sum(degrees)/len(degrees)\n",
    "\n",
    "densityGiant = nx.density(G0)\n",
    "diameterGiant = nx.diameter(G0)\n",
    "transGiant = nx.transitivity(G0)\n",
    "assrtGiant = nx.degree_pearson_correlation_coefficient(G0)\n",
    "avg_path_lenghtGiant = nx.average_shortest_path_length(G0)\n",
    "avg_clustGiant = nx.average_clustering(G0)\n",
    "\n",
    "print(\"avg degree: \", avg_degree)\n",
    "print(\"density: \", densityGiant)\n",
    "print(\"diameter: \", diameterGiant)\n",
    "print(\"avg_path_lenght: \", avg_path_lenghtGiant)\n",
    "print(\"avg_clustering coeff: \", avg_clustGiant)\n",
    "print(\"transitivity: \", transGiant)\n",
    "print(\"assortativity: \", assrtGiant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- assortativity measures of the giant component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,10))\n",
    "plt.title(\"Degree Correlation Matrix\")\n",
    "sns.heatmap(nx.degree_mixing_matrix(G0), cmap=\"coolwarm\").invert_yaxis();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(nx.k_nearest_neighbors(G).values())\n",
    "pairs = sorted(nx.k_nearest_neighbors(G).items(), key=lambda pair:pair[0])\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Average Degree Connectivity\")\n",
    "plt.plot(list(map(lambda pair:pair[1], pairs)))\n",
    "plt.xticks(range(len(pairs)),list(map(lambda pair:pair[0], pairs)))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = list(map(lambda pair: pair[1], sorted(nx.average_neighbor_degree(G).items(), key=lambda pair:pair[0])))\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Average Neighbors Degree Value\")\n",
    "plt.plot(vals, 'o')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does the graph have the same characteristics of a random or a power-law network?**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "def poisson_distr(average, peak, num):\n",
    "    arr = []\n",
    "    rv = poisson(average)\n",
    "    for i in range(num+1):\n",
    "        arr.append(rv.pmf(i)*4.5*peak)\n",
    "        \n",
    "    plt.plot(arr, 'r', linewidth=2.0)\n",
    "\n",
    "def powerLaw_distr(peak, num):\n",
    "    arr = []\n",
    "    for i in range(1,num+2):\n",
    "        arr.append(i**(-2.5)*peak)\n",
    "        \n",
    "    plt.plot(arr, 'r', linewidth=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- Random graph testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random graph has no transitivity or clustering\n",
    "print(\"Transitivity: {}\\nClustering: {}\\nAverage degree: {}\".format(trans, avg_clust, degree_stat.average()))\n",
    "\n",
    "# Degree distribution\n",
    "degree_stat.barplot()\n",
    "poisson_distr(degree_stat.average(),\n",
    "              max(collections.Counter(degree_stat.orderedValues).values()),\n",
    "              degree_stat.maximum()[1])\n",
    "\n",
    "# CONTROLLARE avg_degree > log N if true implies that these networks should be broken into isolated clusters\n",
    "avg_degree > np.log(len(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- Power-law distribution\n",
    "As we seen in the graph below our graph behaves as a power law distribution; many nodes with only a few links, few hubs with large number of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "degree_stat.barplot()\n",
    "powerLaw_distr(max(collections.Counter(degree_stat.orderedValues).values()),\n",
    "              degree_stat.maximum()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which are the most important nodes, with respect to a given centrality measure?**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def most_important(graph, metric, top=10, index=None):\n",
    "    if index is None:\n",
    "        res = sorted(dict(metric(graph)).items(), key=lambda item:item[1], reverse=True)[:top]\n",
    "    else:\n",
    "        res = sorted(dict(metric(graph)[index]).items(), key=lambda item:item[1], reverse=True)[:top]\n",
    "        \n",
    "    return list(map(lambda pair:\"{} ({})\".format(pair[0],round(pair[1],2)), res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = 10\n",
    "\n",
    "#degree\n",
    "print(\"Best {} nodes in terms of degree are:\\n{}\\n\"\n",
    "      .format(display, most_important(G, nx.degree, top=display)))\n",
    "#betweenness\n",
    "print(\"Best {} nodes in terms of betweenness are:\\n{}\\n\"\n",
    "      .format(display, most_important(G, nx.betweenness_centrality, top=display)))\n",
    "#Closeness\n",
    "print(\"Best {} nodes in terms of closeness are:\\n{}\\n\"\n",
    "      .format(display, most_important(G, nx.closeness_centrality, top=display)))\n",
    "#Clustering\n",
    "print(\"Best {} nodes in terms of clustering are:\\n{}\\n\"\n",
    "      .format(display, most_important(G, nx.clustering, top=display)))\n",
    "#Pagerank\n",
    "print(\"Best {} nodes in terms of pagerank are:\\n{}\\n\"\n",
    "      .format(display, most_important(G, nx.pagerank_numpy, top=display)))\n",
    "\n",
    "#HITS\n",
    "print(\"Best {} nodes in terms of HITS are:\\n{}\\n\"\n",
    "      .format(display, most_important(G, nx.hits_numpy, top=display, index=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are the paths short with respect to the size of the network?**<br>\n",
    "if this ratio is near 0 it means that the short paths are much smaller than the network size; as opposite \n",
    "if the value is near 1 it means that the short path is similar to the longest minimum path (geodesic path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_path_lenght/diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the network dense?**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()*2.0/float(G.number_of_nodes()*(G.number_of_nodes()-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
